{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Речь\r\n",
        "\r\n",
        "Все чаще мы ожидаем, что сможем общаться с системами искусственного интеллекта, разговаривая с ними, часто с ожиданием разговорного ответа.\r\n",
        "\r\n",
        "![Говорящий робот](./images/speech.jpg)\r\n",
        "\r\n",
        "*Распознавание речи* (система ИИ, интерпретирующая разговорный язык) и *синтез речи* (система ИИ, генерирующая речевую реакцию) являются ключевыми компонентами решения ИИ по поддержке речи.\r\n",
        "\r\n",
        "## Создание ресурса Cognitive Services\r\n",
        "\r\n",
        "Для создания программного обеспечения, которое может интерпретировать слышимую речь и отвечать на нее в устной форме, можно воспользоваться когнитивной службой **Речь**, которая предоставляет простой способ расшифровки разговорной речи в текст и наоборот.\r\n",
        "\r\n",
        "Если вы еще этого не сделали, воспользуйтесь следующими шагами для создания ресурса **Cognitive Services** в своей подписке Azure.\r\n",
        "\r\n",
        "> **Примечание**. Если у вас уже есть ресурс Cognitive Services, просто откройте его страницу **Быстрый запуск** и скопируйте его ключ и конечную точку в ячейку ниже. В противном случае, выполните следующие шаги для создания.\r\n",
        "\r\n",
        "1. В другой вкладке браузера откройте портал Azure по адресу: https://portal.azure.com, войдя в систему под учетной записью Microsoft.\r\n",
        "2. Нажмите кнопку **&#65291;Создать ресурс**, выполните поиск по запросу *Cognitive Services* и создайте ресурс **Cognitive Services** со следующими параметрами.\r\n",
        "    — **Подписка**: *Ваша подписка Azure*.\r\n",
        "    — **Группа ресурсов**: *Выберите или создайте группу ресурсов с уникальным именем.*.\r\n",
        "    — **Регион**: *Выберите любой доступный регион*:\r\n",
        "    — **Имя**: *Введите уникальное имя*.\r\n",
        "    — **Ценовая категория**: классы S0\r\n",
        "    — **Подтверждаю, что уведомление прочитано и понято**: Выбрано.\r\n",
        "3. Дождитесь завершения развертывания. Затем перейдите на свой ресурс когнитивных служб, и на странице **Обзор** нажмите на ссылку, чтобы управлять ключами для службы. Для подключения к вашему ресурсу когнитивных служб из клиентских приложений вам понадобятся ключ и месторасположение.\r\n",
        "\r\n",
        "### Получение ключа и месторасположения для ресурса Cognitive Services\r\n",
        "\r\n",
        "Для использования ресурса когнитивных служб клиентским приложениям необходимы ключ аутентификации и месторасположение:\r\n",
        "\r\n",
        "1. На портале Azure, на странице **Ключи и конечная точка** вашего ресурса когнитивных служб скопируйте **Ключ1** для своего ресурса и вставьте его в код ниже, заменив **YOUR_COG_KEY**.\r\n",
        "2. Скопируйте **месторасположение** для своего ресурса и вставьте его в код ниже, заменив **YOUR_COG_LOCATION**.\r\n",
        "> **Примечание**. Оставайтесь на странице **Ключи и конечная точка** и скопируйте оттуда **месторасположение** (например: _westus_). Ни в коем случае _не_ добавляйте пробелы между словами в поле «Месторасположение». \r\n",
        "3. Выполните расположенный ниже код, нажав на кнопку **Выполнить код в ячейке** (&#9655) слева от ячейки."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695240794
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Распознавание речи\r\n",
        "\r\n",
        "Предположим, вы хотите построить систему домашней автоматизации, которая принимает голосовые инструкции, такие как «включить свет» или «выключить свет». Ваше приложение должно уметь принимать аудиоввод (вашу устную инструкцию) и интерпретировать его, транскрибируя в текст, который затем можно будет разобрать и проанализировать.\r\n",
        "\r\n",
        "Теперь все готово для расшифровки некоторой речи. Входной сигнал может быть с **микрофона** или из **аудиофайла**. \r\n",
        "\r\n",
        "### Распознавание речи с помощью микрофона\r\n",
        "\r\n",
        "Сначала попробуем с микрофонным входом. Выполните код из ячейки ниже и **немедленно** скажите вслух **«включить свет»**. Возможности преобразования речи в текст службы «Речь» позволят транскрибировать звук. Результатом должна стать ваша речь в виде текста.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import IPython\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# Настройка распознавания речи\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "\n",
        "# Пусть учащиеся скажут: «Включить свет». \r\n",
        "speech_recognizer = SpeechRecognizer(speech_config)\n",
        "\n",
        "# Используйте однократный, синхронный звонок для расшифровки речи\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "print(speech.text)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695250434
        }
      }
    },
    {
      "source": [
        "### (!) Проверка\r\n",
        "\r\n",
        "Смогли ли вы выполнить код из ячейки и перевести свою речь в текст? Если код в вышеприведенной ячейке не дает текстового вывода (пример вывода: _Включить свет._), попробуйте запустить снова выполнить код в ячейке и **немедленно** скажите вслух «Включить свет».\r\n",
        "\r\n",
        "### Распознавание речи с помощью аудиофайла\r\n",
        "\r\n",
        "Если код в вышеприведенной ячейке не дает текстового вывода, возможно, ваш микрофон не настроен на прием входного сигнала. Вместо этого выполните код из ячейки ниже, чтобы увидеть службу «Распознавание речи» в действии с **аудиофайлом** вместо **микрофонного входа**. \r\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from playsound import playsound\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# Получите голосовую команду из аудиофайла\r\n",
        "file_name = 'light-on.wav'\n",
        "audio_file = os.path.join('data', 'speech', file_name)\n",
        "\n",
        "# Настройка распознавания речи\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "audio_config = AudioConfig(filename=audio_file) # Use file instead of default (microphone)\n",
        "speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "# Используйте однократный, синхронный звонок для расшифровки речи\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "# Воспроизвести аудио и показать транскрибированный текст\r\n",
        "playsound(audio_file)\n",
        "print(speech.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Синтез речи\r\n",
        "\r\n",
        "Итак, вы увидели, как служба «Речь» может быть использована для расшифровки речи в текст; а как насчет обратного? Как можно преобразовать текст в речь?\r\n",
        "\r\n",
        "Предположим, что ваша система домашней автоматизации интерпретировала команду на включение света. Соответствующим ответом может быть признание команды устно (а также фактическое выполнение задания!)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
        "%matplotlib inline\n",
        "\n",
        "# Получить текст, который требуется озвучить\r\n",
        "response_text = 'Turning the light on.'\n",
        "\n",
        "# Настройка синтеза речи\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_synthesizer = SpeechSynthesizer(speech_config)\n",
        "\n",
        "# Транскрибируйте текст в речь\r\n",
        "result = speech_synthesizer.speak_text(response_text)\n",
        "\n",
        "# Отобразите соответствующее изображение \r\n",
        "file_name = response_text + \"jpg\"\n",
        "img = Image.open(os.path.join(\"data\", \"speech\", file_name))\n",
        "plt.axis('off')\n",
        "plt. imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695261170
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте изменить переменную **response_text** на *Выключить свет.* (включая точку в конце) и снова выполните код из ячейки, чтобы услышать результат.\r\n",
        "\r\n",
        "## Подробнее\r\n",
        "\r\n",
        "В этой записной книжке вы увидели очень простой пример использования когнитивной службы «Речь». Подробнее о преобразовании [речи в текст](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-speech-to-text) и [текста в речь](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-text-to-speech) см. в документации по службе «Речь»."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.8.5-final",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 32-bit",
      "metadata": {
        "interpreter": {
          "hash": "177429bd1865e7f7a0dbecbac90518c0d9641b1102b2e6c0df4b82dc948b5cb2"
        }
      }
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}