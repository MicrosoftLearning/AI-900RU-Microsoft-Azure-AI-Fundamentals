{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Обнаружение и анализ лиц\r\n",
        "\r\n",
        "Решения для компьютерного зрения часто используют искусственный интеллект для обнаружения, анализа и идентификации человеческих лиц. Или, например, предположим, что розничная компания Northwind Traders решила внедрить «умный магазин», в котором службы ИИ следят за магазином, чтобы выявлять клиентов, нуждающихся в помощи, и направлять к ним сотрудников. Один из способов достижения этого — проведение распознавания и анализа лиц, другими словами, определение наличия лиц на изображениях, и если да, то анализ их черт.\r\n",
        "\r\n",
        "![Робот, анализирующий лицо](./images/face_analysis.jpg)\r\n",
        "\r\n",
        "## Использование когнитивной службы Face («Распознавание лиц») для обнаружения лиц\r\n",
        "\r\n",
        "Предположим, что система умных магазинов, которую хочет создать Northwind Traders, должна иметь возможность обнаруживать клиентов и анализировать черты их лиц. В Microsoft Azure для этого можно использовать **Face**, часть Azure Cognitive Services.\r\n",
        "\r\n",
        "### Создание ресурса Cognitive Services\r\n",
        "\r\n",
        "Давайте начнем с создания ресурса **Cognitive Services** в вашей подписке Azure.\r\n",
        "\r\n",
        "> **Примечание**. Если у вас уже есть ресурс Cognitive Services, просто откройте его страницу **Быстрый запуск** и скопируйте его ключ и конечную точку в ячейку ниже.  В противном случае, выполните следующие шаги для создания.\r\n",
        "\r\n",
        "1. В другой вкладке браузера откройте портал Azure по адресу: https://portal.azure.com, войдя в систему под учетной записью Microsoft.\r\n",
        "2. Нажмите кнопку **&#65291;Создать ресурс**, выполните поиск по запросу *Cognitive Services* и создайте ресурс **Cognitive Services** со следующими параметрами.\r\n",
        "    - **Подписка**: *Ваша подписка Azure*.\r\n",
        "    - **Группа ресурсов**: *Выберите или создайте группу ресурсов с уникальным именем.*.\r\n",
        "    - **Регион**: *Выберите любой доступный регион*:\r\n",
        "    - **Имя**: *Введите уникальное имя*.\r\n",
        "    - **Ценовая категория**: классы S0\r\n",
        "    - **Подтверждаю, что уведомление прочитано и понято**: Выбрано.\r\n",
        "3. Дождитесь завершения развертывания. Затем перейдите на свой ресурс когнитивных служб, и на странице **Обзор** нажмите на ссылку, чтобы управлять ключами для службы. Для подключения к вашему ресурсу когнитивных служб из клиентских приложений вам понадобятся конечная точка и ключи.\r\n",
        "\r\n",
        "### Получение ключа и конечной точки для ресурса Cognitive Services\r\n",
        "\r\n",
        "Для использования ресурса когнитивных служб клиентским приложениям необходимы их конечная точка и ключ аутентификации:\r\n",
        "\r\n",
        "1. На портале Azure, на странице **Ключи и конечная точка** вашего  ресурса когнитивных служб скопируйте **Ключ1** для своего ресурса и вставьте его в код ниже, заменив **YOUR_COG_KEY**.\r\n",
        "\r\n",
        "2. Скопируйте **конечную точку** для своего ресурса и вставьте ее в код ниже, заменив **YOUR_COG_ENDPOINT**.\r\n",
        "\r\n",
        "3. Выполните код в расположенной ниже ячейке с кодом, нажав на кнопку «Выполнить код в ячейке» <span>&#9655;</span> (в верхней левой части ячейки)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693964655
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, когда у вас есть ресурс Cognitive Services, можно использовать службу Face для обнаружения человеческих лиц в магазине.\r\n",
        "\r\n",
        "Чтобы увидеть пример, выполните код из ячейки ниже."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.face import FaceClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from python_code import faces\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Создайте клиент для распознавания лиц.\r\n",
        "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Открытие изображения\r\n",
        "image_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Обнаружение лиц\r\n",
        "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
        "\n",
        "# Отображение лиц (код в python_code/faces.py)\r\n",
        "faces.show_faces(image_path, detected_faces)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693970079
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Каждому обнаруженному лицу присваивается уникальный идентификатор, чтобы ваше приложение могло идентифицировать лица.\r\n",
        "\r\n",
        "Чтобы увидеть идентификаторы еще нескольких лиц покупателей, выполните код из ячейки ниже."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Открытие изображения\r\n",
        "image_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Обнаружение лиц\r\n",
        "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
        "\n",
        "# Отображение лиц (код в python_code/faces.py)\r\n",
        "faces.show_faces(image_path, detected_faces, show_id=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693970447
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Анализ черт лица\r\n",
        "\r\n",
        "Face может делать гораздо больше, чем просто обнаруживать лица. Эта служба также может анализировать черты и выражения лица, чтобы предположить возраст и эмоциональное состояние. Например, выполните приведенный ниже код, чтобы проанализировать черты лица покупателя."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Открыть изображение\r\n",
        "image_path = os.path.join('data', 'face', 'store_cam1.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Обнаружение лиц и указанных черт лица\r\n",
        "attributes = ['age', 'emotion']\n",
        "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
        "\n",
        "# Отображение лиц и черт (код в python_code/faces.py)\r\n",
        "faces.show_face_attributes(image_path, detected_faces)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693971321
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Судя по выявленным на изображении эмоциональным баллах покупателя, покупатель, кажется, вполне доволен процессом покупок.\r\n",
        "\r\n",
        "## Поиск похожих лиц \r\n",
        "\r\n",
        "Идентификаторы лиц, созданные для каждого обнаруженного лица, используются для индивидуальной идентификации лиц. С помощью этих идентификаторов можно сравнить обнаруженное лицо с ранее обнаруженными лицами и найти лица со схожими чертами.\r\n",
        "\r\n",
        "Например, выполните код из ячейки ниже, чтобы сравнить покупателя на одном изображении с покупателями на другом и найти совпадающее лицо."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Получить идентификатор первого лица на изображении 1\r\n",
        "image_1_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
        "image_1_stream = open(image_1_path, \"rb\")\n",
        "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
        "face_1 = image_1_faces[0]\n",
        "\n",
        "# Получить идентификаторы лиц на втором изображении\r\n",
        "image_2_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
        "image_2_stream = open(image_2_path, \"rb\")\n",
        "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
        "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
        "\n",
        "# Найти на изображении 2 лица, похожие на лицо на изображении 1\r\n",
        "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
        "\n",
        "# Отобразить лицо на изображении 1 и аналогичные лица на изображении 2 (код в python_code/face.py)\r\n",
        "faces.show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693972555
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Распознавание лиц\r\n",
        "\r\n",
        "На данный момент вы видели, что Face может обнаруживать лица и черты лица и может идентифицировать два лица, похожие друг на друга. Можно продвинуться дальше, внедрив решение *распознавания лиц*, в котором вы обучаете Face распознавать лицо конкретного человека. Это может быть полезно в различных сценариях, например при автоматическом помечании фотографий друзей в приложении для социальных сетей или для использования распознавания лиц как части системы биометрической идентификации.\r\n",
        "\r\n",
        "Чтобы увидеть, как это работает, предположим, что компания Northwind Traders хочет использовать распознавание лиц, чтобы гарантировать, что только авторизованные сотрудники IT-отдела могут получить доступ к защищенным системам.\r\n",
        "\r\n",
        "Начнем с создания *группы лиц*, представляющих авторизованных сотрудников."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "group_id = 'employee_group_id'\n",
        "try:\n",
        "    # Delete group if it already exists\n",
        "    face_client.person_group.delete(group_id)\n",
        "except Exception as ex:\n",
        "    print(ex.message)\n",
        "finally:\n",
        "    face_client.person_group.create(group_id, 'employees')\n",
        "    print ('Group created!')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693973492
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, когда *группа лиц* существует, можно добавить *человека* для каждого сотрудника, которого мы хотим включить в группу, а затем зарегистрировать несколько фотографий каждого человека, чтобы служба Face могла узнать отличительные черты лица каждого человека. В идеале на фотографиях должен быть изображен один и тот же человек в разных позах и с разными выражениями лица.\r\n",
        "\r\n",
        "Мы добавим одного сотрудника по имени Уэндел и зарегистрируем три фотографии этого сотрудника."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Добавить человека (Уэндела) в группу\r\n",
        "wendell = face_client.person_group_person.create(group_id, 'Wendell')\n",
        "\n",
        "# Сфотографировать Уэндела\r\n",
        "folder = os.path.join('data', 'face', 'wendell')\n",
        "wendell_pics = os.listdir(folder)\n",
        "\n",
        "# Зарегистрировать фотографии\r\n",
        "i = 0\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "for pic in wendell_pics:\n",
        "    # Add each photo to person in person group\n",
        "    img_path = os.path.join(folder, pic)\n",
        "    img_stream = open(img_path, \"rb\")\n",
        "    face_client.person_group_person.add_face_from_stream(group_id, wendell.person_id, img_stream)\n",
        "\n",
        "    # Display each image\n",
        "    img = Image.open(img_path)\n",
        "    i +=1\n",
        "    a=fig.add_subplot(1,len(wendell_pics), i)\n",
        "    a.axis('off')\n",
        "    imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693976898
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавляя людей и регистрируя фотографии, мы можем обучать Face распознаванию каждого человека."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "face_client.person_group.train(group_id)\n",
        "print('Trained!')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693977046
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, когда модель обучена, ее можно использовать для идентификации распознанных лиц на изображении."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Получить идентификаторы лиц на втором изображении\r\n",
        "image_path = os.path.join('data', 'face', 'employees.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "image_faces = face_client.face.detect_with_stream(image=image_stream)\n",
        "image_face_ids = list(map(lambda face: face.face_id, image_faces))\n",
        "\n",
        "# Получить имена распознанных лиц\r\n",
        "face_names = {}\n",
        "recognized_faces = face_client.face.identify(image_face_ids, group_id)\n",
        "for face in recognized_faces:\n",
        "    person_name = face_client.person_group_person.get(group_id, face.candidates[0].person_id).name\n",
        "    face_names[face.face_id] = person_name\n",
        "\n",
        "# отобразить распознанные лица\r\n",
        "faces.show_recognized_faces(image_path, image_faces, face_names)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693994820
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подробнее\r\n",
        "\r\n",
        "Подробнее о когнитивной службе Face см. в [документации по Face](https://docs.microsoft.com/azure/cognitive-services/face/).\r\n"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}